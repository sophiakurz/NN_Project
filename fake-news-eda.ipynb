{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekhya/anaconda3/envs/fakenews/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fincantieri, Naval Group may exchange stakes i...</td>\n",
       "      <td>MILAN (Reuters) - Italy s Fincantieri and Fran...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>September 28, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Fincantieri, Naval Group may exchange stakes i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WATCH: Celebrities Unite To Send POWERFUL Mes...</td>\n",
       "      <td>December 19th could be the day 38 electors ste...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 14, 2016</td>\n",
       "      <td>0</td>\n",
       "      <td>WATCH: Celebrities Unite To Send POWERFUL Mes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HILARIOUS! TRUMP SUPPORTER Uses Berkeley Riot ...</td>\n",
       "      <td>Pepsi got hammered by just about everyone for ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Apr 15, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>HILARIOUS! TRUMP SUPPORTER Uses Berkeley Riot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>House to unveil Obamacare bill after next week</td>\n",
       "      <td>WASHINGTON (Reuters) - Republican lawmakers pl...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>February 16, 2017</td>\n",
       "      <td>1</td>\n",
       "      <td>House to unveil Obamacare bill after next week...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump returns to hardline position on illegal ...</td>\n",
       "      <td>PHOENIX (Reuters) - Republican presidential no...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>September 1, 2016</td>\n",
       "      <td>1</td>\n",
       "      <td>Trump returns to hardline position on illegal ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Fincantieri, Naval Group may exchange stakes i...   \n",
       "1   WATCH: Celebrities Unite To Send POWERFUL Mes...   \n",
       "2  HILARIOUS! TRUMP SUPPORTER Uses Berkeley Riot ...   \n",
       "3     House to unveil Obamacare bill after next week   \n",
       "4  Trump returns to hardline position on illegal ...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  MILAN (Reuters) - Italy s Fincantieri and Fran...     worldnews   \n",
       "1  December 19th could be the day 38 electors ste...          News   \n",
       "2  Pepsi got hammered by just about everyone for ...      politics   \n",
       "3  WASHINGTON (Reuters) - Republican lawmakers pl...  politicsNews   \n",
       "4  PHOENIX (Reuters) - Republican presidential no...  politicsNews   \n",
       "\n",
       "                  date  label  \\\n",
       "0  September 28, 2017       1   \n",
       "1    December 14, 2016      0   \n",
       "2         Apr 15, 2017      0   \n",
       "3   February 16, 2017       1   \n",
       "4   September 1, 2016       1   \n",
       "\n",
       "                                             content  \n",
       "0  Fincantieri, Naval Group may exchange stakes i...  \n",
       "1   WATCH: Celebrities Unite To Send POWERFUL Mes...  \n",
       "2  HILARIOUS! TRUMP SUPPORTER Uses Berkeley Riot ...  \n",
       "3  House to unveil Obamacare bill after next week...  \n",
       "4  Trump returns to hardline position on illegal ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the datasets\n",
    "true_df = pd.read_csv(\"News _dataset/True.csv\")\n",
    "fake_df = pd.read_csv(\"News _dataset/Fake.csv\")\n",
    "\n",
    "# Add labels \n",
    "true_df['label'] = 1\n",
    "fake_df['label'] = 0\n",
    "\n",
    "# Combine and shuffle datasets\n",
    "df = pd.concat([true_df, fake_df]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Use only title+text for classification\n",
    "df['content'] = df['title'] + ' ' + df['text']\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "# Split \n",
    "train_text, val_text, train_label, val_label = train_test_split(df['content'], df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title      0\n",
      "text       0\n",
      "subject    0\n",
      "date       0\n",
      "label      0\n",
      "content    0\n",
      "dtype: int64\n",
      "label\n",
      "0    23481\n",
      "1    21417\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for nulls\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check class imbalance\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "sns.countplot(x=\"label\", data=df)\n",
    "plt.title(\"Class Distribution (0: Fake, 1: Real)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No null values.\n",
    "\n",
    "Classes are not too imbalanced!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize with BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "train_encodings = tokenizer(\n",
    "    list(train_text), truncation=True, padding=True, max_length=512\n",
    ")\n",
    "\n",
    "val_encodings = tokenizer(\n",
    "    list(val_text), truncation=True, padding=True, max_length=512\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, label):\n",
    "        self.encodings = encodings\n",
    "        self.label = label\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            key: torch.tensor(val[idx]) for key, val in self.encodings.items()\n",
    "        } | {\"labels\": torch.tensor(self.label[idx])}\n",
    "\n",
    "train_dataset = NewsDataset(train_encodings, list(train_label))\n",
    "val_dataset = NewsDataset(val_encodings, list(val_label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 8.86 GB, other allocations: 194.67 MB, max allowed: 9.07 GB). Tried to allocate 192.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m      3\u001b[39m training_args = TrainingArguments(\n\u001b[32m      4\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33m./results\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m      5\u001b[39m     num_train_epochs=\u001b[32m3\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     logging_steps=\u001b[32m10\u001b[39m\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m trainer = Trainer(\n\u001b[32m     13\u001b[39m     model=model,\n\u001b[32m     14\u001b[39m     args=training_args,\n\u001b[32m     15\u001b[39m     train_dataset=train_dataset,\n\u001b[32m     16\u001b[39m     eval_dataset=val_dataset\n\u001b[32m     17\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fakenews/lib/python3.11/site-packages/transformers/trainer.py:2245\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2243\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fakenews/lib/python3.11/site-packages/transformers/trainer.py:2560\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2553\u001b[39m context = (\n\u001b[32m   2554\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2555\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2556\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2557\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2558\u001b[39m )\n\u001b[32m   2559\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2560\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2562\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2563\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2564\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2565\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2566\u001b[39m ):\n\u001b[32m   2567\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2568\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fakenews/lib/python3.11/site-packages/transformers/trainer.py:3736\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3733\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   3735\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m3736\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3738\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   3739\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3740\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3741\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   3742\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fakenews/lib/python3.11/site-packages/transformers/trainer.py:3801\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3799\u001b[39m         loss_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   3800\u001b[39m     inputs = {**inputs, **loss_kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m3801\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3802\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   3803\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fakenews/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fakenews/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fakenews/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1675\u001b[39m, in \u001b[36mBertForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1667\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1668\u001b[39m \u001b[33;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[32m   1669\u001b[39m \u001b[33;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[32m   1670\u001b[39m \u001b[33;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[32m   1671\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m   1672\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1673\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1675\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1676\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1677\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1680\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1681\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1682\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1683\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1685\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1687\u001b[39m pooled_output = outputs[\u001b[32m1\u001b[39m]\n\u001b[32m   1689\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.dropout(pooled_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fakenews/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fakenews/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fakenews/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1144\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1137\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m   1138\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m   1139\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m   1140\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m   1141\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m   1142\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m-> \u001b[39m\u001b[32m1144\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1145\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1146\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1156\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1157\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fakenews/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fakenews/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fakenews/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[39m, in \u001b[36mBertEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    684\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    685\u001b[39m         layer_module.\u001b[34m__call__\u001b[39m,\n\u001b[32m    686\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    692\u001b[39m         output_attentions,\n\u001b[32m    693\u001b[39m     )\n\u001b[32m    694\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m695\u001b[39m     layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    706\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fakenews/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fakenews/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fakenews/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:585\u001b[39m, in \u001b[36mBertLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    574\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    575\u001b[39m     hidden_states: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    582\u001b[39m ) -> Tuple[torch.Tensor]:\n\u001b[32m    583\u001b[39m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[32m    584\u001b[39m     self_attn_past_key_value = past_key_value[:\u001b[32m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m585\u001b[39m     self_attention_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    586\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    587\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    588\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    592\u001b[39m     attention_output = self_attention_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    594\u001b[39m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fakenews/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fakenews/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fakenews/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:515\u001b[39m, in \u001b[36mBertAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    505\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    506\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    507\u001b[39m     hidden_states: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    513\u001b[39m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    514\u001b[39m ) -> Tuple[torch.Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m     self_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    524\u001b[39m     attention_output = \u001b[38;5;28mself\u001b[39m.output(self_outputs[\u001b[32m0\u001b[39m], hidden_states)\n\u001b[32m    525\u001b[39m     outputs = (attention_output,) + self_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fakenews/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fakenews/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/fakenews/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:440\u001b[39m, in \u001b[36mBertSdpaSelfAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    432\u001b[39m \u001b[38;5;66;03m# We dispatch to SDPA's Flash Attention or Efficient kernels via this `is_causal` if statement instead of an inline conditional assignment\u001b[39;00m\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# in SDPA to support both torch.compile's dynamic shapes and full graph options. An inline conditional prevents dynamic shapes from compiling.\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;66;03m# The tgt_len > 1 is necessary to match with AttentionMaskConverter.to_causal_4d that does not create\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[38;5;66;03m# a causal mask in case tgt_len == 1.\u001b[39;00m\n\u001b[32m    436\u001b[39m is_causal = (\n\u001b[32m    437\u001b[39m     \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cross_attention \u001b[38;5;129;01mand\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tgt_len > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    438\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m attn_output = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout_prob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    449\u001b[39m attn_output = attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    450\u001b[39m attn_output = attn_output.reshape(bsz, tgt_len, \u001b[38;5;28mself\u001b[39m.all_head_size)\n",
      "\u001b[31mRuntimeError\u001b[39m: MPS backend out of memory (MPS allocated: 8.86 GB, other allocations: 194.67 MB, max allowed: 9.07 GB). Tried to allocate 192.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\", \n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training and Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metrics\n",
    "train_acc = [x['eval_accuracy'] for x in trainer.state.log_history if 'eval_accuracy' in x]\n",
    "eval_steps = [x['step'] for x in trainer.state.log_history if 'eval_accuracy' in x]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(eval_steps, train_acc, label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Validation Accuracy over Time\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fakenews",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
